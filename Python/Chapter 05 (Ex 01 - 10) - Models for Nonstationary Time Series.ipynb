{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Models for Nonstationary Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5.1**.  Identify the following as specific ARIMA models.  That is, what are the $p$, $d$, and $q$ and what are the values of the parameters (the $\\phi$'s and $\\theta$'s)?\n",
    "\n",
    "**(a)** $ Y_t = Y_{t-1} - 0.25 Y_{t-2} + e_t - 0.1 e_{t-1} $\n",
    "\n",
    "**(b)** $ Y_t = 2 Y_{t-1} - Y_{t-2} + e_t $\n",
    "\n",
    "**(c)** $ Y_t = 0.5 Y_{t-1} - 0.5 Y_{t-2} + e_t - 0.5 e_{t-1} + 0.25 e_{t-2} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)** This is an ARMA(2, 1) model, or ARIMA(2, 0, 1), with $p = 2$, $d = 0$, $q = 1$, where $\\phi_1 = 1$, $\\phi_2 = -0.25$, and $\\theta_1 = -0.1$.  Checking stationarity conditions: $\\phi_1 + \\phi_2 = 0.75 < 1$, $\\phi_2 - \\phi_1 = -1.25 < 1$, and $|\\phi_2| = 0.25 < 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)**  This is the I(2) model, or ARIMA(0, 2, 0), with $p = 0, d = 2, q = 0$.  This occurs as $\\nabla^2 Y_t = \\nabla (Y_t - Y_{t - 1}) = Y_t - 2Y_{t-1} + Y_{t-2} = e_t$ is just a white noise process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** This is an ARMA(2, 2) model, or ARIMA(2, 0, 2), with $p = 2, d = 0, q = 2$, where $\\phi_1 = 0.5$, $\\phi_2 = -0.5$, $\\theta_1 = -0.5$, and $\\theta_2 = 0.25$.  Checking stationarity conditions:  $\\phi_1 + \\phi_2 = 0 < 1$, $\\phi_2 - \\phi_1 = -1 < 1$, and $|\\phi_2| = 0.5 < 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5.2**.  For each of the ARIMA models below, give the values for $\\text{E}[\\nabla Y_t]$ and $\\text{Var}[\\nabla Y_t]$.\n",
    "\n",
    "**(a)** $Y_t = 3 + Y_{t-1} + e_t - 0.75e_{t-1}$.\n",
    "\n",
    "**(b)** $Y_t = 10 + 1.25 Y_{t-1} - 0.25 Y_{t-2} + e_t - 0.1 e_{t-1}$.\n",
    "\n",
    "**(c)** $Y_t = 5 + 2 Y_{t-1} - 1.7 Y_{t-2} + 0.7 Y_{t-3} + e_t - 0.5 e_{t-1} + 0.25 e_{t-2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)**  We have \n",
    "\n",
    "$$ \\nabla Y_t = W_t = 3 + e_t - 0.75 e_{t-1} $$\n",
    "\n",
    "so $\\{W_t\\}$ is a MA(1) process.  From first principles,\n",
    "\n",
    "$$ \\text{E}[\\nabla Y_t] = 3 + \\text{E}[e_t] - 0.5 \\text{E}[e_{t-1}] = 3 $$\n",
    "\n",
    "and\n",
    "\n",
    "$$ \\text{Var}[\\nabla Y_t] = \\text{Var}[e_t] + (0.75)^2 \\text{Var}[e_{t-1}] = 1.5625 \\sigma_e^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** We have\n",
    "\n",
    "$$ \\nabla Y_t = W_t = 10 + 0.25 W_{t-1} + e_t - 0.1 e_{t-1} $$\n",
    "\n",
    "so $\\{W_t\\}$ is an ARMA(1, 1) stationary process with $\\phi = 0.25$ and $\\theta = 0.1$.  Therefore, the mean is\n",
    "\n",
    "$$ \\mu = \\text{E}[W_t] = 10 + 0.25 \\text{E}[W_{t - 1}] + \\text{E}[e_t] - 0.1 \\text{E}[e_t] = 10 + 0.25 \\mu $$\n",
    "\n",
    "and so $\\mu = 10 / (1 - 0.25) = 40 / 3$.\n",
    "\n",
    "The variance is, from equation 4.4.4,\n",
    "\n",
    "$$ \\gamma_0 = \\text{Var}[\\nabla Y_t] = \\frac{1 - 2 \\phi \\theta + \\theta^2}{1 - \\phi^2} \\sigma_e^2 = 1.024 \\sigma_e^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)**  We have\n",
    "\n",
    "$$ \\nabla Y_t = W_t = 5 + W_{t-1} - 0.7 W_{t-2} + e_t - 0.5 e_{t-1} + 0.25 e_{t-2} $$\n",
    "\n",
    "so $\\{W_t\\}$ is an ARMA(2, 2) stationary process with $\\phi_1 = 1$, $\\phi_2 = -0.7$, $\\theta_1 = 0.5$ and $\\theta_2 = -0.25$. \n",
    "\n",
    "Therefore, the mean satisfies\n",
    "\n",
    "$$ \\mu = \\text{E}[W_t] \n",
    "= 5 + \\text{E}[W_{t-1}] - 0.7 \\text{E}[W_{t-2}] \n",
    "+ \\text{E}[e_t] - 0.5 \\text{E}[e_{t-1}] + 0.25 \\text{E}[e_{t-2}]\n",
    "= 5 + \\mu - 0.7 \\mu $$\n",
    "\n",
    "and so $\\mu = 50 / 7$.\n",
    "\n",
    "Now, the system of equations for autocovariance in ARMA (equation 4.C.4) states that:\n",
    "\n",
    "$$\n",
    "\\begin{array}{ldl}\n",
    "\\gamma_0 &=& \\phi_1 \\gamma_1 + \\phi_2 \\gamma_2 - \\sigma_e^2 (\\theta_0 + \\theta_1 \\psi_1 + \\theta_2 \\psi_2) \\\\\n",
    "\\gamma_1 &=& \\phi_1 \\gamma_0 + \\phi_2 \\gamma_1 - \\sigma_e^2 (\\theta_1 + \\theta_2 \\psi_1) \\\\\n",
    "\\gamma_2 &=& \\phi_1 \\gamma_1 + \\phi_2 \\gamma_0 - \\sigma_e^2 \\theta_2\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "where the $\\psi$-weights are (from equation 4.4.7)\n",
    "\n",
    "$$\n",
    "\\begin{array}{lcl}\n",
    "\\psi_0 &=& 1 \\\\\n",
    "\\psi_1 &=& -\\theta_1 + \\phi_1 \\\\\n",
    "\\psi_2 &=& -\\theta_2 + \\phi_2 + \\phi_1 \\psi_1\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Solving, we get $(\\psi_0, \\psi_1, \\psi_2) = (1, 0.5, 0.05)$ and\n",
    "\n",
    "$$\n",
    "\\begin{array}{lcl}\n",
    "\\gamma_0 &=& \\gamma_1 -0.7 \\gamma_2 - 1.2375 \\sigma_e^2 \\\\\n",
    "\\gamma_1 &=& \\gamma_0 -0.7 \\gamma_1 - 0.375 \\sigma_e^2 \\\\\n",
    "\\gamma_2 &=& \\gamma_1 -0.7 \\gamma_0 + 0.25 \\sigma_e^2 \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$$ \\text{Var}[\\nabla Y_t] = \\gamma_0 \\approx 4.433 \\sigma_e^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5.3**.  Suppose that $\\{Y_t\\}$ is generated according to $Y_t = e_t + ce_{t-1} + ce_{t-2} + ce_{t-3} + \\cdots + ce_0$ for $t > 0$.\n",
    "\n",
    "**(a)**  Find the mean and covariance functions for $\\{Y_t\\}$.  Is $\\{Y_t\\}$ stationary?\n",
    "\n",
    "**(b)**  Find the mean and covariance functions for $\\{\\nabla Y_t\\}$.  Is $\\{\\nabla Y_t\\}$ stationary?\n",
    "\n",
    "**(c)**  Identify $\\{Y_t\\}$ as a specific ARIMA process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)**  The mean is\n",
    "\n",
    "$$ \\text{E}[Y_t] = \\text{E}\\left[ e_t + c \\sum_{k=1}^t e_{t-k} \\right] = \\text{E}[e_t] + c \\sum_{k=1}^t \\text{E}[e_{t-k}] = 0$$\n",
    "\n",
    "and the variance is\n",
    "\n",
    "$$ \\text{Var}[Y_t] = \\text{Var}\\left[ e_t + c \\sum_{k=1}^t e_{t-k} \\right] = \\text{Var}[e_t] + c^2 \\sum_{k=1}^t \\text{Var}[e_{t-k}] = (1 + tc^2) \\sigma_e^2 $$\n",
    "\n",
    "which varies with $t$ for $c \\neq 0$, and so the series isn't stationary.\n",
    "\n",
    "The covariance is, for $k > 0$,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{Cov}[Y_t, Y_{t-k}] &= \\text{Cov}\\left[ e_t + c \\sum_{j=1}^t e_{t-j},  e_{t-k} + c \\sum_{j=1}^{t - k} e_{t-j-k} \\right] \\\\\n",
    "&= \\text{Cov}\\left[ c e_{t-k} + c \\sum_{j=1}^{t - k} e_{t-j-k},  e_{t-k} + c \\sum_{j=1}^{t - k} e_{t-j-k} \\right] \\\\\n",
    "&= c (1 + ct) \\sigma_e^2\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)**  By definition,\n",
    "\n",
    "$$ \\nabla Y_t = Y_t - Y_{t-1} = e_t + (c-1) e_{t-1} $$\n",
    "\n",
    "which is a MA(1) series in general (for $c \\neq 1$) and just the white noise process when $c = 1$.  The mean is:\n",
    "\n",
    "$$ \\text{E}[\\nabla Y_t] = \\text{E}[e_t] + (c - 1) \\text{E}[e_{t-1}] = 0 $$\n",
    "\n",
    "and the autocovariance in general is\n",
    "\n",
    "$$ \\text{Cov}[Y_t, Y_{t-k}] = \\text{Cov}[e_t + (c-1)e_{t-1}, e_{t-k} + (c-1)e_{t-k}] = \\begin{cases}\n",
    "(c^2 - 2c + 2) \\sigma_e^2 &\\text{for } k = 0 \\\\\n",
    "(c-1) \\sigma_e^2 &\\text{for } k = 1 \\\\\n",
    "0 &\\text{for } k > 1\n",
    "\\end{cases} $$\n",
    "\n",
    "The $\\{ \\nabla Y_t \\}$ process is MA(1), and is stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)**  Since $\\{\\nabla Y_t\\}$ is MA(1), then $\\{ Y_t\\}$ is ARIMA(0, 1, 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5.4**.  Suppose that $Y_t = A + Bt + X_t$, where $\\{X_t\\}$ is a random walk.  First suppose that $A$ and $B$ are constants.\n",
    "\n",
    "**(a)**  Is $\\{Y_t\\}$ stationary?\n",
    "\n",
    "**(b)**  Is $\\{\\nabla Y_t\\}$ stationary?\n",
    "\n",
    "Now suppose that $A$ and $B$ are random variables that are independent of the random walk $\\{X_t\\}$.\n",
    "\n",
    "**(c)**  Is $\\{Y_t\\}$ stationary?\n",
    "\n",
    "**(d)**  Is $\\{\\nabla Y_t\\}$ stationary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)**  No.  The mean is a function of $t$,\n",
    "\n",
    "$$ \\text{E}[Y_t] = A + Bt + \\text{E}[X_t] = A + Bt $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)**  Yes.  We have:\n",
    "\n",
    "$$ \\nabla Y_t = B + \\nabla X_t $$\n",
    "\n",
    "and $\\{\\nabla X_t\\}$ is a white noise process, so $\\{\\nabla Y_t\\}$ is white noise with shifted mean $B$, and so is stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)**  Still no.  We now have\n",
    "\n",
    "$$ \\text{E}[Y_t] = \\mu_A + \\mu_B t + \\text{E}[X_t] = \\mu_A + \\mu_B t $$\n",
    "\n",
    "which is, in general, a function of $t$, unless $\\mu_B = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d)**  Yes.  We still have\n",
    "\n",
    "$$ \\nabla Y_t = B + \\nabla X_t $$\n",
    "\n",
    "and $\\{ \\nabla X_t \\}$ is a white noise process, so $\\{ \\nabla Y_t \\}$ is white noise with the whole process shifted by the same random variable $B$, which is stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5.5**.  Using the simulated white noise values in Exhibit 5.2, on page 88, verify the values shown for the explosive p process Y_t."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.30000e-01, 6.40000e-01, 3.72000e+00, 1.26700e+01, 3.95700e+01,\n",
       "       1.19330e+02, 3.58630e+02, 1.07491e+03])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "e_t = np.array([0.63, -1.25, 1.80, 1.51, 1.56, 0.62, 0.64, -0.98])\n",
    "Y_t = np.empty(len(e_t))\n",
    "\n",
    "Y_t[0] = e_t[0]\n",
    "for t in range(1, len(e_t)):\n",
    "    Y_t[t] = 3 * Y_t[t-1] + e_t[t]\n",
    "    \n",
    "Y_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5.6**.  Consider a stationary process $\\{Y_t\\}$.  Show that if $\\rho_1 < \\frac{1}{2}$, $\\nabla Y_t$ has a larger variance than does $Y_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**.  We have:\n",
    "\n",
    "$$ \\text{Var}[\\nabla Y_t] = \\text{Var}[Y_t - Y_{t-1}] = \\text{Var}[Y_t] + \\text{Var}[Y_{t-1}] - 2\\text{Cov}[Y_t, Y_{t-1}] = 2(\\gamma_0 - \\gamma_1)$$\n",
    "\n",
    "But $\\gamma_1 = \\rho_1 \\gamma_0$, so \n",
    "\n",
    "$$ \\text{Var}[\\nabla Y_t] = 2(\\gamma_0 - \\gamma_1) = 2 \\gamma_0 (1 - \\rho_1) > \\gamma_0 \\left( 2 \\left(1 - \\frac{1}{2}\\right) \\right) = \\gamma_0 = \\text{Var}[Y_t] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5.7**.  Consider two models:\n",
    "\n",
    "$$\n",
    "\\begin{array}{cl}\n",
    "A:& Y_t = 0.9 Y_{t-1} + 0.09 Y_{t-2} + e_t \\\\\n",
    "B:& Y_t = Y_{t-1} + e_t - 0.1 e_{t-1}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "**(a)**  Identify each as a specific ARIMA model.  That is, what are the $p$, $d$, and $q$ and what are the values of the parameters, $\\phi$'s and $\\theta$'s?\n",
    "\n",
    "**(b)**  In what way are the two models different?\n",
    "\n",
    "**(c)**  In what ways are the two models similar?  (Compare $\\psi$-weights and $\\pi$-weights.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)**  \n",
    "\n",
    "- Model A is AR(2), or ARIMA(2, 0, 0), with $p = 2$, $d = 0$, $q = 0$, and $\\phi_1 = 0.9$ and $\\phi_2 = 0.09$.\n",
    "- Model B is IMA(1, 1), or ARIMA(0, 1, 1), with $p = 0$, $d = 1$, $q = 1$, and $\\theta_1 = 0.1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b and c)**  The $\\psi$-values are the factors for the regression as expressed based on the white noise terms,\n",
    "\n",
    "$$ Y_t = e_t + \\sum_{j=1}^\\infty \\psi_j e_{t - j} $$\n",
    "\n",
    "while the $\\pi$-values are the factors for the regression as expressed based on the previous terms in the process,\n",
    "\n",
    "$$ Y_t = e_t + \\sum_{j=1}^\\infty \\pi_j Y_{t - j} $$\n",
    "\n",
    "For model A, we have\n",
    "\n",
    "$$ \\psi_k = \\frac{G_1^{k+1} - G_2^{k+1}}{G_1 - G_2}\n",
    "\\quad \\text{and} \\quad\n",
    "\\pi_k = \\begin{cases}\n",
    "0.9 &\\text{for } k = 1 \\\\\n",
    "0.09 &\\text{for } k = 2 \\\\\n",
    "0 &\\text{for } k > 2\n",
    "\\end{cases} $$\n",
    "\n",
    "where $G_1$, $G_2$ are the inverse of the roots of the characteristic equation $1 - \\phi_1 x - \\phi_2 x^2 = 0$:\n",
    "\n",
    "$$ \n",
    "G_1 = \\frac{\\phi_1 - \\sqrt{\\phi_1^2 + 4 \\phi_2}}{2} \\approx -0.091\n",
    "\\quad \\text{and} \\quad\n",
    "G_2 = \\frac{\\phi_1 + \\sqrt{\\phi_1^2 + 4 \\phi_2}}{2} \\approx 0.9908\n",
    "$$\n",
    "\n",
    "For model B, we have\n",
    "\n",
    "$$ \\psi_k = 0.9 \\text{ for all } k\n",
    "\\quad \\text{and} \\quad\n",
    "\\pi_k = \\begin{cases}\n",
    "1 &\\text{for } k = 1 \\\\\n",
    "-0.9 \\cdot (0.1)^{k - 2} &\\text{for } k > 1\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "In the $\\psi$-value interpretation, both models keep track of an arbitrarily large number of white noise processes ($\\psi_k \\neq 0$ for all $k$), though the AR process has the influence of errors decreasing over time while the IMA process just accumulates them without decay.\n",
    "\n",
    "In the $\\pi$-value interpretation, model A has a finite representation, while model B has an infinite representation.  Both the previous values of $\\pi$ in model A provide positive feedback ($\\pi_k \\geq 0$), while from the second term on in model B there is negative feedback ($\\pi_k < 0$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5.8**.  Consider a nonstationary \"AR(1)\" process defined as a solution to Equation (5.1.2) on page 88, with $|\\phi| > 1$.\n",
    "\n",
    "**(a)**  Derive an equation similar to Equation (5.1.3) on page 88, for this more general case.  Use $Y_0 = 0$ as an initial condition.\n",
    "\n",
    "**(b)**  Derive an equation similar to Equation (5.1.4) on page 89, for this more general case.\n",
    "\n",
    "**(c)**  Derive an equation similar to Equation (5.1.5) on page 89, for this more general case.\n",
    "\n",
    "**(d)**  Is it true that for any $|\\phi| > 1$, $\\text{Corr}[Y_t, Y_{t-k})] \\approx 1$ for large $t$ and moderate $k$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)**  Expanding the recursion $Y_t = \\phi Y_{t-1} + e_t$, we get\n",
    "\n",
    "$$ Y_t = \\sum_{k=0}^{t-1} \\phi^{k} e_{t - k} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** \n",
    "\n",
    "$$ \\text{Var}[Y_t] = \\text{Var}\\left[ \\sum_{k=0}^{t-1} \\phi^{k} e_{t - k} \\right] \n",
    "= \\sum_{k=0}^{t-1} \\phi^{2k} \\text{Var}[e_{t-k}]\n",
    "= \\sigma_e^2 \\sum_{k=0}^{t-1} \\phi^{2k}\n",
    "= \\frac{\\phi^{2t} - 1}{\\phi^2 - 1} \\sigma_e^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** \n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "\\text{Cov}[Y_t, Y_{t-k}] &= \\text{Cov}\\left[ \\sum_{i=0}^{t-1} \\phi^{i} e_{t - i}, \\sum_{j=0}^{t-1-k} \\phi^{j} e_{t - j} \\right] \\\\\n",
    "&= \\sum_{j=0}^{t-1-k} \\phi^{2j + k} \\text{Var}[e_{t-j}] \\\\\n",
    "&= \\phi^k \\sigma_e^2 \\sum_{j=0}^{t-1-k} \\phi^{2j + k} \\\\\n",
    "&= \\sigma_e^2 \\phi^k \\frac{\\phi^{2(t - k)} - 1}{\\phi^2 - 1}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d)**  We have\n",
    "\n",
    "$$ \\text{Corr}[Y_t, Y_{t-k}] = \\frac{\\text{Cov}[Y_t, Y_{t-k}]}{\\sqrt{\\text{Var}[Y_t]\\cdot\\text{Var}[Y_{t-k}]}}\n",
    "= \\phi^k \\sqrt{\\frac{\\phi^{2(t - k)} - 1}{\\phi^{2t} - 1}}\n",
    "$$\n",
    "\n",
    "which is still approximately 1 for large $t$ and moderate $k$, as \n",
    "\n",
    "$$ \\lim_{t \\rightarrow \\infty} \\frac{\\phi^{2(t - k)} - 1}{\\phi^{2t} - 1} = \\lim_{t \\rightarrow \\infty} \\frac{\\phi^{2(t - k)}}{\\phi^{2t}} = \\phi^{-2k} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5.9**.  Verify Equation (5.1.10) on page 90."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**.  The equation states that, for a process $\\{Y_t\\}$ with\n",
    "\n",
    "$$ Y_t = M_t + e_t \\quad \\text{with} \\quad M_t = M_{t-1} + \\varepsilon_r $$\n",
    "\n",
    "where $\\{e_t\\}$ and $\\{\\varepsilon_t\\}$ are independent white noise series, then\n",
    "\n",
    "$$ \\nabla Y_t = \\nabla M_t + \\nabla e_t = \\varepsilon_t + e_t - e_{t-1} $$\n",
    "\n",
    "has the autocorrelation of a MA(1) series with\n",
    "\n",
    "$$ \\rho_1 = -\\frac{1}{2 + \\sigma_\\varepsilon^2/\\sigma_e^2} $$\n",
    "\n",
    "Verifying: the variance of the difference series is\n",
    "\n",
    "$$ \\text{Var}[\\nabla Y_t] = \\text{Var}[\\varepsilon_t] + \\text{Var}[e_t] + \\text{Var}[e_{t-1}] = \\sigma_\\varepsilon^2 + 2 \\sigma_e^2 $$\n",
    "\n",
    "and the first autocovariance is\n",
    "\n",
    "$$ \\text{Cov}[\\nabla Y_t, \\nabla Y_{t-1}] = \\text{Cov}[\\varepsilon_t + e_t - e_{t-1}, \\varepsilon_{t-1} + e_{t-1} - e_{t-2}] = -\\text{Var}[e_{t-1}] = -\\sigma_e^2 $$ \n",
    "\n",
    "therefore the first autocorrelation is\n",
    "\n",
    "$$ \\rho_1 = \\frac{-\\sigma_e^2}{\\sigma_\\varepsilon^2 + 2 \\sigma_e^2} = -\\frac{1}{2 + \\sigma_\\varepsilon^2/\\sigma_e^2} $$\n",
    "\n",
    "as stated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5.10**.  Nonstationary ARIMA series can be simulated by first simulating the corresponding stationary ARMA series and then \"integrating\" it (really partially summing it).  Use statistical software to simulate a variety of IMA(1, 1) and IMA(2, 2) series with a variety of parameter values.  Note any stochastic \"trends\" in the simulated series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**.\n",
    "\n",
    "A generic IMA(1, 1) series has the form\n",
    "\n",
    "$$ A_t = A_{t-1} + e_t - \\theta e_{t-1} $$\n",
    "\n",
    "and a generic IMA(2, 2) series has the form\n",
    "\n",
    "$$ B_t = 2 B_{t-1} - B_{t-2} + e_t - \\theta_1 e_{t-1} - \\theta_2 e_{t-2} $$\n",
    "\n",
    "The corresponding ARMA processes are\n",
    "\n",
    "$$ \\nabla A_t = e_t - \\theta e_{t-1} $$\n",
    "\n",
    "and\n",
    "\n",
    "$$ \\nabla^2 B_t = e_t - \\theta_1 e_{t-1} - \\theta_2 e_{t-2} $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
