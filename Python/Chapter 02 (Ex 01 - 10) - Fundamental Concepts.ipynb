{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fundamental Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2.1**. Suppose $\\text{E}[X] = 2$, $\\text{Var}[X] = 9$, $\\text{E}[Y] = 0$, $\\text{Var}[Y] = 4$, and $\\text{Corr}(X, Y) = 0.25$.  Find:\n",
    "\n",
    "**(a)** $\\text{Var}[X + Y]$\n",
    "\n",
    "**(b)** $\\text{Cov}[X, X + Y]$\n",
    "\n",
    "**(c)** $\\text{Corr}[X + Y, X - Y]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)** Note that $\\text{Cov}[X, Y] = \\text{Corr}[X, Y] \\sqrt{\\text{Var}[X] \\text{Var}[Y]} = 0.25 \\cdot \\sqrt{9 \\cdot 4} = 1.5$.  Then,\n",
    "\n",
    "$$\\text{Var}[X + Y] = \\text{Var}[X] + \\text{Var}[Y] + \\text{Cov}[X, Y] = 9 + 4 + 1.5 = 14.5$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)**\n",
    "\n",
    "$$ \\text{Cov}[X, X + Y] = \\text{Cov}[X, X] + \\text{Cov}[X, Y] = \\text{Var}[X] + \\text{Cov}[X, Y] = 9 + 1.5 = 10.5 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)**\n",
    "\n",
    "Computing the covariance:\n",
    "\n",
    "$$ \\text{Cov}[X + Y, X - Y] = \\text{Cov}[X, X] - \\text{Cov}[X, Y] + \\text{Cov}[X, Y] - \\text{Cov}[Y, Y] = \\text{Var}[X] - \\text{Var}[Y] = 9 - 4 = 5 $$\n",
    "\n",
    "Computing the variance of $X + Y$:\n",
    "\n",
    "$$ \\text{Var}[X + Y] = \\text{Var}[X] + \\text{Var}[Y] + \\text{Cov}[X, Y] = 9 + 4 + 1.5 = 14.5 $$\n",
    "\n",
    "Computing the variance of $X - Y$:\n",
    "\n",
    "$$ \\text{Var}[X - Y] = \\text{Var}[X] + \\text{Var}[Y] - \\text{Cov}[X, Y] = 9 + 4 - 1.5 = 11.5 $$\n",
    "\n",
    "So,\n",
    "\n",
    "$$ \\text{Corr}[X + Y, X - Y] = \\frac{\\text{Cov}[X + Y, X - Y]}{\\sqrt{\\text{Var}[X + Y] \\text{Var}[X - Y]}} = \\frac{5}{\\sqrt{14.5 \\cdot 11.5}} \\approx 0.3872 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2.2**.  If $X$ and $Y$ are dependent but $\\text{Var}[X] = \\text{Var}[Y]$, find $\\text{Cov}[X + Y, X - Y]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**.\n",
    "\n",
    "$$ \\text{Cov}[X + Y, X - Y] = \\text{Cov}[X, X] - \\text{Cov}[X, Y] + \\text{Cov}[X, Y] - \\text{Cov}[Y, Y] = \\text{Var}[X] - \\text{Var}[Y] = 0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2.3**.  Let $X$ have a distribution with mean $\\mu$ and variance $\\sigma^2$, and let $Y_t = X$ for all $t$.\n",
    "\n",
    "**(a)** Show that $\\{ Y_t \\}$ is strictly and weakly stationary.\n",
    "\n",
    "**(b)** Find the autocovariance function for $\\{ Y_t \\}$.\n",
    "\n",
    "**(c)** Sketch a \"typical\" time plot of $\\{ Y_t \\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)**  By definition, the distribution of $Y_{t_1}, Y_{t_2}, \\dots, Y_{t_n}$ is $n$ identical copies of a sample drawn from $X$, which is the same as the distribution of $Y_{t_1 - k}, Y_{t_2 - k}, \\dots, Y_{t_n - k}$ for any $k$, therefore $\\{Y_t\\}$ is strictly stationary.\n",
    "\n",
    "The mean function is $\\mu$ for all $t$, so it is constant over time, and the autocovariance function is $\\gamma_{t, t - k} = \\text{Cov}[Y_t, Y_{t - k}] = \\text{Var}[X] = \\sigma^2$ is also constant for all time $t$ and lag $k$, and so $\\{Y_t\\}$ is weakly stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)**  As shown in (a), the covariance function is\n",
    "\n",
    "$$ \\gamma_{t, s} = \\text{Cov}[Y_t, Y_s] = \\text{Var}[X] = \\sigma^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)**  A \"typical\" time plot of $\\{ Y_t \\}$ is a constant series, with all values equal to some value drawn from the distribution of $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "X = 3 * np.ones(10)\n",
    "nn = np.arange(1, 11)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(nn, X, marker='o', markerfacecolor='none', linestyle='solid', ms=5, markeredgecolor='blue')\n",
    "plt.xlabel(r'$t$')\n",
    "plt.ylabel(r'$Y_t$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2.4**.  Let $\\{ e_t \\}$ be a zero mean white noise process.  Suppose that the observed process is $Y_t = e_t + \\theta e_{t - 1}$, where $\\theta$ is either 3 or 1/3.\n",
    "\n",
    "**(a)** Find the autocorrelation function for $\\{ Y_t \\}$ both when $\\theta = 3$ and when $\\theta = 1/3$.\n",
    "\n",
    "**(b)** You should have discovered that the time series is stationary regardless of the value of $\\theta$ and that the autocorrelation functions are the same for $\\theta = 3$ and $\\theta = 1/3$.  For simplicity, suppose that the process mean is known to be zero and the variance of $Y_t$ is known to be 1.  You observe the series $\\{Y_t\\}$ for $t = 1, 2, \\dots, n$ and suppose that you can produce good estimates of the autocorrelations $\\rho_k$.  Do you think that you could determine which value of $\\theta$ is correct (3 or 1/3) based on the estimate of $\\rho_k$?  Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)**  The variance is:\n",
    "\n",
    "$$ \\text{Var}[Y_t] = \\text{Var}[e_t + \\theta e_{t - 1}] = \\text{Var}[e_t] + \\theta^2 \\text{Var}[e_{t - 1}] = (1 + \\theta^2) \\sigma_e^2 $$\n",
    "\n",
    "Also\n",
    "\n",
    "$$\n",
    "\\text{Cov}[Y_t, Y_{t - 1}] = \\text{Cov}[e_t + \\theta e_{t - 1}, e_{t - 1} + \\theta e_{t - 2}] = \\theta \\text{Var}[e_{t-1}] = \\theta \\sigma_2^2\n",
    "$$\n",
    "\n",
    "and for element pairs with lag $k > 1$,\n",
    "\n",
    "$$ \\text{Cov}[Y_t, Y_{t - k}] = \\text{Cov}[e_t + \\theta e_{t - 1}, e_{t - k} + \\theta e_{t - k - 1}] = 0 $$\n",
    "\n",
    "Therefore, the autocovariance function is\n",
    "\n",
    "$$ \\gamma_{t, s} = \\begin{cases}\n",
    "(1 + \\theta^2) \\sigma_e^2 &\\text{for } | t - s | = 0 \\\\\n",
    "\\theta \\sigma_e^2         &\\text{for } | t - s | = 1 \\\\\n",
    "0                         &\\text{for } | t - s | > 1\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "and the autocorrelation function is\n",
    "\n",
    "$$ \\rho_{t, s} = \\begin{cases}\n",
    "1                            &\\text{for } | t - s | = 0 \\\\\n",
    "\\theta / (1 + \\theta^2)      &\\text{for } | t - s | = 1 \\\\\n",
    "0                            &\\text{for } | t - s | > 1\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Note that $\\theta / (1 + \\theta^2) = 0.3$ for both $\\theta = 3$ and $\\theta = 1/3$ (this likely being the point of the exercise), so in either scenario the autocorrelation function is\n",
    "\n",
    "$$ \\rho_{t, s} = \\begin{cases}\n",
    "1        &\\text{for } | t - s | = 0 \\\\\n",
    "0.3      &\\text{for } | t - s | = 1 \\\\\n",
    "0        &\\text{for } | t - s | > 1\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)**  As shown in (a) and stated on the exercise, the series will have the same autocorrelation whether $\\theta = 3$ or $\\theta = 1/3$, so estimates of this property cannot be used to distinguish between the two candidate models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2.5**.  Suppose $Y_t = 5 + 2t + X_t$, where $\\{ X_t \\}$ is zero-mean stationary series with autocovariance function $\\gamma_k$.\n",
    "\n",
    "**(a)** Find the mean function for $\\{ Y_t \\}$.\n",
    "\n",
    "**(b)** Find the autocovariance function for $\\{ Y_t \\}$.\n",
    "\n",
    "**(c)** Is $\\{ Y_t \\}$ stationary?  Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)** \n",
    "\n",
    "$$ \\mu_t = \\text{E}[Y_t] = \\text{E}[5 + 2t + X_t] = 5 + 2t + \\text{E}[X_t] = 5 + 2t $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** The covariance for terms with lag $k$ is\n",
    "\n",
    "$$ \\text{Cov}[Y_t, Y_{t - k}] = \\text{Cov}[5 + 2t + X_t, 5 + 2(t - k) + X_{t - k}] = \\text{Cov}[X_t, X_{t - k}] = \\gamma_k $$\n",
    "\n",
    "Therefore, the autocovariance function for $\\{Y_t\\}$ is the same as the autocovariance function for $\\{X_t\\}$, $\\gamma_k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** The series $\\{Y_t\\}$ is not stationary because the mean is not constant over time -- there is a time drift term, $2t$, in the mean function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2.6**.  Let $\\{ X_t \\}$ be a stationary time series, and let \n",
    "\n",
    "$$ Y_t = \\begin{cases}\n",
    "X_t &\\text{for } t \\text{ odd} \\\\\n",
    "X_t + 3 &\\text{for } t \\text{ even}\n",
    "\\end{cases} $$\n",
    "\n",
    "**(a)**  Show that $\\text{Cov}[Y_t, Y_{t - k}]$ is free of $t$ for all lags $k$.\n",
    "\n",
    "**(b)**  Is $\\{ Y_t \\}$ stationary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)**  For every possible parity combination of $t$ and $k$ we have:\n",
    "\n",
    "- Even $t$, even $k$:  $\\text{Cov}[Y_t, Y_{t - k}] = \\text{Cov}[X_t + 3, X_{t - k} + 3] = \\text{Cov}[X_t, X_{t - k}] $\n",
    "- Even $t$, odd $k$:  $\\text{Cov}[Y_t, Y_{t - k}] = \\text{Cov}[X_t + 3, X_{t - k}] = \\text{Cov}[X_t, X_{t - k}] $\n",
    "- Odd $t$, even $k$:  $\\text{Cov}[Y_t, Y_{t - k}] = \\text{Cov}[X_t, X_{t - k}] $\n",
    "- Odd $t$, odd $k$:  $\\text{Cov}[Y_t, Y_{t - k}] = \\text{Cov}[X_t, X_{t - k} + 3] = \\text{Cov}[X_t, X_{t - k}] $\n",
    "\n",
    "Since $\\{X_t\\}$ is stationary, $\\text{Cov}[X_t, X_{t - k}]$ is free of $t$, and so $\\text{Cov}[Y_t, Y_{t - k}]$ is free of $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)**  No, as its mean function is not constant over time.  Given that $\\{ X_t \\}$ is stationary, it has a constant mean $\\overline{X}$, and we have\n",
    "\n",
    "$$ \\text{E}[Y_t] = \\begin{cases}\n",
    "\\overline{X} &\\text{for } t \\text{ odd} \\\\\n",
    "\\overline{X} + 3 &\\text{for } t \\text{ even}\n",
    "\\end{cases} $$\n",
    "\n",
    "is not constant over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2.7**.  Suppose that $\\{Y_t\\}$ is stationary with autocovariance function $\\gamma_k$.\n",
    "\n",
    "**(a)**  Show that $W_t = \\nabla Y_t = Y_t - Y_{t - 1}$ is stationary by finding the mean and the autocovariance function for $\\{ W_t \\}$.\n",
    "\n",
    "**(b)**  Show that $U_t = \\nabla^2 Y_t = \\nabla[Y_t - Y_{t - 1}] = Y_t - 2 Y_{t - 1} + Y_{t - 2}$ is stationary.  (You need not find the mean and autocovariance function for $\\{U_t\\}$.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)**  Since $\\{Y_t\\}$ has a constant mean $\\overline{Y}$ over time, the mean of $W_t$ is\n",
    "\n",
    "$$ \\text{E}[W_t] = \\text{E}[Y_t - Y_{t - 1}] = \\text{E}[Y_t] - \\text{E}[Y_{t - 1}] = \\overline{Y} - \\overline{Y} = 0 $$\n",
    "\n",
    "The variance of $W_t$ is\n",
    "\n",
    "$$ \\text{Var}[W_t] = \\text{Var}[Y_t - Y_{t - 1}] = \\gamma_1 $$\n",
    "\n",
    "The variance of $W_t$ with lag $k \\geq 1$ is\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "\\text{Cov}[W_t, W_{t - k}] &= \\text{Cov}[Y_t - Y_{t - 1}, Y_{t - k} - Y_{t - k - 1}] \\\\\n",
    "&= \\text{Cov}[Y_t, Y_{t - k}] - \\text{Cov}[Y_t,  Y_{t - k - 1}] - \\text{Cov}[Y_{t - 1}, Y_{t - k}] + \\text{Cov}[Y_{t - 1}, Y_{t - k - 1}] \\\\\n",
    "&= 2 \\gamma_k - \\gamma_{k + 1} - \\gamma_{k - 1}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "therefore the autocovariance function for $\\{W_t\\}$ is\n",
    "\n",
    "$$ \\omega_k = \\begin{cases}\n",
    "\\gamma_1 &\\text{for } k = 0 \\\\\n",
    "2 \\gamma_k - \\gamma_{k + 1} - \\gamma_{k - 1} &\\text{for } k > 0\n",
    "\\end{cases} $$\n",
    "\n",
    "Since the autocovariance function is free of $k$ and the mean is constant over time, then $\\{W_t\\} is stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)**  Applying the result of (a) to the series $\\{ W_t \\}$ rather than $ \\{ Y_t \\}$, we get that the series $\\{U_t\\} = \\{ \\nabla W_t \\}$ must also be stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2.8**.  Suppose that $\\{Y_t\\}$ is stationary with autocovariance function $\\gamma_k$.  Show that for any positive integer $n$ and any constants $c_1, c_2, \\dots c_n$ the process $\\{ W_t \\}$ defined by $W_t = c_1 Y_t + c_2 Y_{t - 1} + \\cdots + c_n Y_{t - n + 1}$ is stationary.  (Note that Exercise 2.7 is a special case of this result)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**.  If the mean of $\\{Y_t\\}$ is $\\overline{Y}$, then the mean of $\\{W_t\\}$ is\n",
    "\n",
    "$$ \\text{E}[W_t] = \\text{E}\\left[ \\sum_{i=1}^n c_i Y_{t - i + 1} \\right] = \\sum_{i=1}^n c_i \\text{E}[Y_{t - i + 1}] = \\overline{Y} \\sum_{i=1}^n c_i $$\n",
    "\n",
    "which is constant over time.\n",
    "\n",
    "The variance of $W_t$ with lag $k \\geq 0$ is\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "\\text{Cov}[W_t, W_{t - k}] &= \\text{Cov}\\left[ \\sum_{i=1}^n c_i Y_{t - i + 1}, \\sum_{j=1}^n c_i Y_{t - j + 1 - k}\\right] \\\\\n",
    "&= \\sum_{i=1}^n \\sum_{j=1}^n c_i c_j \\text{Cov} [ Y_{t - i + 1}, Y_{t - j + 1 - k} ]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "and since the difference in the indices of $\\text{Cov} [ Y_{t - i + 1}, Y_{t - j + 1 - k} ]$ does not depend on $t$, no matter which index is largest, then the overall expression is always a linear combination of the autocovariance function $\\gamma_m$ for $0 \\leq m \\leq n + k - 1$,\n",
    "\n",
    "$$ \\text{Cov}[W_t, W_{t - k}] = \\sum_{m=0}^{n + k - 1} d_{m, k} \\gamma_m $$\n",
    "\n",
    "for some constants $d_{m, k}$ that do not depend on $t$.  Therefore, $\\{W_t\\}$ is stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2.9**.  Suppose $Y_t = \\beta_0 + \\beta_1 t + X_t$, where $\\{X_t\\}$ is a zero-mean stationary series with autocovariance function $\\gamma_k$ and $\\beta_0$ and $\\beta_1$ are constants.\n",
    "\n",
    "**(a)**  Show that $\\{ Y_t \\}$ is not stationary but that $W_t = \\nabla Y_t = Y_t - Y_{t - 1}$ is stationary.\n",
    "\n",
    "**(b)**  In general, show that if $Y_t = \\mu_t + X_t$, where $\\{ X_t \\}$ is a zero-mean stationary series and $\\mu_t$ is a polynomial in $t$ of degree $d$, then $\\nabla^m Y_t = \\nabla (\\nabla^{m - 1} Y_t)$ is stationary for $m \\geq d$ and nonstationary for $0 \\leq m \\leq d$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)**  We have\n",
    "\n",
    "$$ \\text{E}[Y_t] = \\text{E}[\\beta_0 + \\beta_1 t + X_t] = \\beta_0 + \\beta_1 t + \\overline{X} $$\n",
    "\n",
    "so the mean of $Y_t$ is not constant in time, and so $\\{Y_t\\}$ is not stationary.\n",
    "\n",
    "On the other hand, the mean of $\\{W_t\\}$ is constant in time,\n",
    "\n",
    "$$ \\text{E}[W_t] = \\text{E}[Y_t - Y_{t - 1}] = \\text{E}[Y_t] - \\text{E}[Y_{t - 1}] = \\beta_1 $$\n",
    "\n",
    "The variance of $W_t$ is\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "\\text{Var}[W_t] &= \\text{Var}[Y_t - Y_{t - 1}] \\\\\n",
    "&= \\text{Var}[\\beta_0 + \\beta_1 t + X_t - \\beta_0 - \\beta_1 (t - 1) - X_{t - 1}] \\\\\n",
    "&= \\text{Var}[\\beta_1 + X_t - X_{t - 1}] \\\\\n",
    "&= \\text{Var}[X_t - X_{t - 1}] \\\\\n",
    "&= \\text{Var}{X_t} + \\text{Var}[X_{t - 1}] - 2 \\text{Cov}[X_t, X_{t - 1}] \\\\\n",
    "&= 2\\gamma_0 - 2\\gamma_1\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "while the covariance of $W_t$ for lag $k > 0$ is\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "\\text{Cov}[W_t, W_{t - k}] &= \\text{Cov}[Y_t - Y_{t - 1}, Y_{t - k} - Y_{t - k - 1}] \\\\\n",
    "&= \\text{Cov}[\\beta_0 + \\beta_1 t + X_t - \\beta_0 - \\beta_1 (t - 1) - X_{t - 1}, \n",
    "\\beta_0 + \\beta_1 (t - k) + X_{t - k} - \\beta_0 - \\beta_1 (t - k - 1) - X_{t - k - 1}] \\\\\n",
    "&= \\text{Cov}[\\beta_1 + X_t - X_{t - 1}, \\beta_1 + X_{t - k} -  X_{t - k - 1}] \\\\\n",
    "&= \\text{Cov}[X_t - X_{t - 1}, X_{t - k} -  X_{t - k - 1}] \\\\\n",
    "&= \\text{Cov}[X_t, X_{t - k}] - \\text{Cov}[X_t, X_{t - k - 1}] - \\text{Cov}[X_{t - 1}, X_{t - k - 1}] + \\text{Cov}[X_{t - 1}, X_{t - k - 1}] \\\\\n",
    "&= 2\\gamma_k - \\gamma_{k + 1} - \\gamma_{k - 1}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "and so the autocovariance function for $\\{W_t\\}$ does not depend on $t$,\n",
    "\n",
    "$$ \\omega_k = \\begin{cases}\n",
    "\\gamma_1 &\\text{for } k = 0 \\\\\n",
    "2 \\gamma_k - \\gamma_{k + 1} - \\gamma_{k - 1} &\\text{for } k > 0\n",
    "\\end{cases} $$\n",
    "\n",
    "Since $\\{W_t\\}$ has a constant mean in time and an autocovariance function that does not depend on time, it is stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)**  \n",
    "\n",
    "**Lemma 2.9.1**: if $\\{Y_t\\}$ is stationary, then $\\{ \\nabla Y_t \\}$ must also be stationary.\n",
    "\n",
    "**Proof**:\n",
    "\n",
    "- The mean of $\\{ \\nabla Y_t \\}$ constant (and zero):\n",
    "\n",
    "$$ \\text{E}[\\nabla Y_t] = \\text{E}[Y_t - Y_{t - 1}] = \\text{E}[Y_t] - \\text{E}[Y_{t - 1}] = \\overline{Y} - \\overline{Y} = 0 $$\n",
    "\n",
    "- Assuming $\\{Y_t\\}$ has autocovariance function $\\gamma_k$, the variance of $\\{ \\nabla Y_t \\}$ is:\n",
    "\n",
    "  $$ \\text{Var}[ \\nabla Y_t ] = \\text{Var}[Y_t - Y_{t - 1}] = \\text{Var}{Y_t} + \\text{Var}[Y_{t - 1}] - 2 \\text{Cov}[Y_t, Y_{t - 1}] = 2\\gamma_0 - 2 \\gamma_1 $$\n",
    "\n",
    "  and the autocovariance for lag $k > 0$ is\n",
    "  \n",
    "  $$ \n",
    "  \\begin{align}\n",
    "  \\text{Cov}[\\nabla Y_t, \\nabla Y_{t - k}] &= \\text{Cov}[Y_t - Y_{t - 1}, Y_{t - k} - Y_{t - k - 1}] \\\\\n",
    "  &= \\text{Cov}[Y_t, Y_{t - k}] - \\text{Cov}[Y_t, Y_{t - k - 1}] - \\text{Cov}[Y_{t - 1}, Y_{t - k - 1}] + \\text{Cov}[Y_{t - 1}, Y_{t - k - 1}] \\\\\n",
    "&= 2\\gamma_k - \\gamma_{k + 1} - \\gamma_{k - 1}\n",
    "  \\end{align}\n",
    "  $$\n",
    "  \n",
    "Therefore $\\{\\nabla Y_t\\}$ has a constant mean and an autocovariance function that does not depend on time, and so it is stationary.\n",
    "\n",
    "**Lemma 2.9.2**: If $\\mu_t$ is a polynomial of degree $d$, then $\\nabla^k \\mu_t = \\nabla(\\nabla^{k - 1}\\mu_t - \\nabla^{k - 1}\\mu_{t - 1})$ is a polynomial of degree $d - 1$, for $1 \\leq k \\leq d$.\n",
    "\n",
    "**Proof**: Let $\\mu_t = \\sum_{j=0}^d c_j t^j$, for constants $c_j$.  \n",
    "\n",
    "- For $k = 1$, $\\nabla \\mu_t = \\mu_t - \\mu_{t - 1} = \\sum_{j=1}^d c_j (t^j - (t - 1)^j) $.  In each term, the coefficients of $t^j$ in $t^j$ and $(t - 1)^j$ cancel out, so $t^j - (t - 1)^j$ is a polynomial of degree $j - 1$, and the overall expression is a polynomial of degree $d - 1$.\n",
    "- For $k > 1$, $\\nabla^k \\mu_t = \\nabla(\\nabla^{k - 1}\\mu_t - \\nabla^{k - 1}\\mu_{t - 1}) = \\nabla (a_t - a_{t - 1})$, where $a_t$ is a polynomial of degree $d - k + 1$ by induction, therefore $\\nabla^k \\mu_t$ is a polynomial of degree $d - k$.\n",
    "\n",
    "Now, we can prove the result from (b) by induction.  \n",
    "\n",
    "- Base case $d = 0$:  This is equivalent to Lemma 2.9.1.\n",
    "\n",
    "- Base case $d = 1$:  This is equivalent to the result in (a).\n",
    "\n",
    "- Induction step:\n",
    "  - If $m < d$, then $\\nabla_m Y_t$ is a polynomial $A$ in $t$ with degree $d - m$, plus a linear combination of $X_t, X_{t - 1}, \\dots, X_{t - m}$.  Therefore the expected value of $\\nabla_m Y_t$ is  $\\text{E}[A(t) - A(t - 1) + \\sum c_j X_j] = A(t) - A(t - 1) + \\overline{X} \\sum c_j$, which is a non-constant function of $t$.  Therefore the mean is not constant in time, and so $\\{ \\nabla^m Y_t \\}$ is not stationary.\n",
    "  - If $m > d$, then $\\nabla_m Y_t$ is a linear combination of $X_t, X_{t - 1}, \\dots, X_{t - m}$ (using Lemma 2.9.2, applying $\\nabla$ enough times zeroes out the polynomial component).  Therefore, from Lemma 2.9.1, $\\{ \\nabla^m Y_t \\}$ is stationary.\n",
    "  - If $m = d$, then $\\nabla_m Y_t$ is a zero degree polynomial (a constant) plus a linear combination of of $X_t, X_{t - 1}, \\dots, X_{t - m}$ (using Lemma 2.9.2, applying $\\nabla$ enough times to bring the degree down to exactly 0).  Therefore, the expectation of $\\nabla^m Y_t$ is that constant plus $\\overline{X} \\sum c_j$, and so it does not change with time.  The zero-polynomial constant only scales up the covariance terms by a constant factor, and so the autocovariance also does not depend on the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2.10**.  Let $\\{X_t\\}$ be a zero-mean, unit-variance stationary process with autocorrelation function $\\rho_k$.  Suppose that $\\mu_t$ is a nonconstant function and that $\\sigma_t$ is a positive-valued nonconstant function.  The observed series is formed as $Y_t = \\mu_t + \\sigma_t X_t$.\n",
    "\n",
    "**(a)**  Find the mean and the covariance function for the $\\{ Y_t \\}$ process.\n",
    "\n",
    "**(b)**  Show that the autocorrelation function for the $\\{ Y_t \\}$ process depends only on the time lag.  Is the $\\{Y_t\\}$ process stationary?\n",
    "\n",
    "**(c)**  Is it possible to have a time series with a constant mean and with $\\text{Corr}[Y_t, Y_{t - k}]$ free of $t$ but with $\\{Y_t\\}$ not stationary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)**  The mean of the process is:\n",
    "\n",
    "$$ \\text{E}[Y_t] = \\text{E}[\\mu_t + \\sigma_t X_t] = \\mu_t + \\sigma_t \\text{E}[X_t] = \\mu_t $$\n",
    "\n",
    "and the covariance function is\n",
    "\n",
    "$$ \\text{Cov}[Y_t, Y_s] = \\text{Cov}[\\mu_t + \\sigma_t X_t, \\mu_s + \\sigma_s X_s] = \\sigma_t \\sigma_s \\text{Cov}[X_t, X_s] = \\sigma_t \\sigma_s \\rho_{t - s}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)**  The autocorrelation for the $\\{ Y_t \\}$ process is\n",
    "\n",
    "$$ \\text{Corr}[Y_t, Y_{t - k}] = \\frac{\\text{Cov}[Y_t, Y_{t - k}]}{\\sqrt{\\text{Var}[Y_t] \\text{Var}[Y_{t - k}]}} = \\frac{\\sigma_t \\sigma_{t - k} \\rho_k}{\\sqrt{\\sigma_t^2 \\sigma_{t - k}^2}} = \\rho_k $$\n",
    "\n",
    "that is, it is the same as the autocorrelation for the $\\{X_t\\}$ process, and it depends only on the time lag.\n",
    "\n",
    "Note that this does not make the process stationary, both because it has nonconstant mean $\\mu_t$ and because stationarity requires time-independent autocovariance, not time-independent autocorrelation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** Yes -- for example, take $\\{X_t\\}$ as some series with more than two distinct non-zero autocorrelation values, make $\\mu_t = 0$ and $\\sigma_t = t$.  Then, even though $\\{Y_t\\}$ has constant mean 0, the autocovariance depends on the time,\n",
    "\n",
    "$$ \\text{Cov}[Y_t, Y_{t - k}] = \\sigma_t \\sigma_{t - k} \\rho_k = t(t-k) \\rho_k$$\n",
    "\n",
    "despite that $\\text{Corr}[Y_t, Y_{t - k}] = \\rho_k$ is free of $t$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
